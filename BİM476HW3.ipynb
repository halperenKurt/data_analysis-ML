{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "P0r9C3X3vqTf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, classification_report\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 1:** DATASET PREPARATION"
      ],
      "metadata": {
        "id": "yCdPEmCq5PoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Churn_Modelling.csv\")"
      ],
      "metadata": {
        "id": "5q7eh7RxyfJT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_instances, n_attributes = df.shape\n",
        "print(f\"Number of Instances: {n_instances}\")\n",
        "print(f\"Number of Attributes: {n_attributes}\")\n",
        "\n",
        "# 2. Report Class distribution [cite: 175]\n",
        "print(\"\\nClass Distribution (Exited):\")\n",
        "print(df['Exited'].value_counts())\n",
        "print(df['Exited'].value_counts(normalize=True)) # Percentage\n",
        "\n",
        "# 3. Display first 8-10 instances [cite: 176]\n",
        "print(\"\\nFirst 10 instances of the dataset:\")\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AJ8lFx611k4",
        "outputId": "0e3b7792-ba40-48e9-8274-0361d2b892c9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Instances: 10000\n",
            "Number of Attributes: 14\n",
            "\n",
            "Class Distribution (Exited):\n",
            "Exited\n",
            "0    7963\n",
            "1    2037\n",
            "Name: count, dtype: int64\n",
            "Exited\n",
            "0    0.7963\n",
            "1    0.2037\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "First 10 instances of the dataset:\n",
            "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
            "0          1    15634602  Hargrave          619    France  Female   42   \n",
            "1          2    15647311      Hill          608     Spain  Female   41   \n",
            "2          3    15619304      Onio          502    France  Female   42   \n",
            "3          4    15701354      Boni          699    France  Female   39   \n",
            "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
            "5          6    15574012       Chu          645     Spain    Male   44   \n",
            "6          7    15592531  Bartlett          822    France    Male   50   \n",
            "7          8    15656148    Obinna          376   Germany  Female   29   \n",
            "8          9    15792365        He          501    France    Male   44   \n",
            "9         10    15592389        H?          684    France    Male   27   \n",
            "\n",
            "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
            "0       2       0.00              1          1               1   \n",
            "1       1   83807.86              1          0               1   \n",
            "2       8  159660.80              3          1               0   \n",
            "3       1       0.00              2          0               0   \n",
            "4       2  125510.82              1          1               1   \n",
            "5       8  113755.78              2          1               0   \n",
            "6       7       0.00              2          1               1   \n",
            "7       4  115046.74              4          1               0   \n",
            "8       4  142051.07              2          0               1   \n",
            "9       2  134603.88              1          1               1   \n",
            "\n",
            "   EstimatedSalary  Exited  \n",
            "0        101348.88       1  \n",
            "1        112542.58       0  \n",
            "2        113931.57       1  \n",
            "3         93826.63       0  \n",
            "4         79084.10       0  \n",
            "5        149756.71       1  \n",
            "6         10062.80       0  \n",
            "7        119346.88       1  \n",
            "8         74940.50       0  \n",
            "9         71725.73       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
        "print(\"Dropped columns: RowNumber, CustomerId, Surname\")\n",
        "\n",
        "df_clean = pd.get_dummies(df_clean, columns=['Geography'], drop_first=True)\n",
        "\n",
        "le = LabelEncoder()\n",
        "df_clean['Gender'] = le.fit_transform(df_clean['Gender'])\n",
        "print(\"Encoded 'Geography' and 'Gender'.\")\n",
        "\n",
        "X = df_clean.drop('Exited', axis=1)\n",
        "y = df_clean['Exited']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "print(f\"Data split into Train ({X_train.shape[0]}) and Test ({X_test.shape[0]}) sets.\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
        "\n",
        "print(\"Feature scaling completed.\")\n",
        "print(\"\\nPreprocessing complete. Data is ready for Model Training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DClyFRMPfnbK",
        "outputId": "6d0c2f61-5f4d-469d-cacb-387bf94ecf51"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped columns: RowNumber, CustomerId, Surname\n",
            "Encoded 'Geography' and 'Gender'.\n",
            "Data split into Train (7000) and Test (3000) sets.\n",
            "Feature scaling completed.\n",
            "\n",
            "Preprocessing complete. Data is ready for Model Training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 2:** MANUAL ATTRIBUTE SELECTION CALCULATIONS"
      ],
      "metadata": {
        "id": "OkPu4BWP5dcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Create the small synthetic dataset\n",
        "data = {\n",
        "    'Credit': ['High', 'Low', 'High', 'Low', 'Low', 'High', 'High', 'Low', 'High', 'Low'],\n",
        "    'HasCard': ['Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No'],\n",
        "    'Active': ['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes'],\n",
        "    'Exited': ['No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes']\n",
        "}\n",
        "df_small = pd.DataFrame(data)\n",
        "\n",
        "# 2. Define Helper Functions\n",
        "def calculate_entropy(target_col):\n",
        "    elements, counts = np.unique(target_col, return_counts=True)\n",
        "    entropy = 0\n",
        "    for count in counts:\n",
        "        p = count / len(target_col)\n",
        "        entropy -= p * np.log2(p)\n",
        "    return entropy\n",
        "\n",
        "def calculate_gini(target_col):\n",
        "    elements, counts = np.unique(target_col, return_counts=True)\n",
        "    impurity = 1\n",
        "    for count in counts:\n",
        "        p = count / len(target_col)\n",
        "        impurity -= p**2\n",
        "    return impurity\n",
        "\n",
        "# 3. Calculate System Metrics\n",
        "total_entropy = calculate_entropy(df_small['Exited'])\n",
        "total_gini = calculate_gini(df_small['Exited'])\n",
        "\n",
        "print(f\"System Entropy (S): {total_entropy:.4f}\")\n",
        "print(f\"System Gini (S): {total_gini:.4f}\")\n",
        "\n",
        "# 4. Calculate Metrics for Each Attribute\n",
        "results = []\n",
        "for col in ['Credit', 'HasCard', 'Active']:\n",
        "    vals, counts = np.unique(df_small[col], return_counts=True)\n",
        "    weighted_entropy = 0\n",
        "    weighted_gini = 0\n",
        "    split_info = 0\n",
        "\n",
        "    for i in range(len(vals)):\n",
        "        p = counts[i] / np.sum(counts)\n",
        "        subset = df_small[df_small[col] == vals[i]]\n",
        "\n",
        "        weighted_entropy += p * calculate_entropy(subset['Exited'])\n",
        "        weighted_gini += p * calculate_gini(subset['Exited'])\n",
        "        split_info -= p * np.log2(p)\n",
        "\n",
        "    info_gain = total_entropy - weighted_entropy\n",
        "    gain_ratio = info_gain / split_info if split_info != 0 else 0\n",
        "\n",
        "    results.append({\n",
        "        'Attribute': col,\n",
        "        'Info Gain': info_gain,\n",
        "        'Gain Ratio': gain_ratio,\n",
        "        'Gini Index': weighted_gini\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nAttribute Selection Measures:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzQWPWAG13et",
        "outputId": "3bb599ce-2d30-45a5-c606-a51af35369bc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System Entropy (S): 0.9710\n",
            "System Gini (S): 0.4800\n",
            "\n",
            "Attribute Selection Measures:\n",
            "  Attribute  Info Gain  Gain Ratio  Gini Index\n",
            "0    Credit   0.609987    0.609987    0.160000\n",
            "1   HasCard   0.019973    0.020571    0.466667\n",
            "2    Active   0.019973    0.020571    0.466667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 3:** Implementing Classification Models"
      ],
      "metadata": {
        "id": "ev5Whi1aoJOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_results = {}\n",
        "\n",
        "dt_model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "k_values = [3, 5, 11]\n",
        "knn_results = {}\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "    y_pred_knn = knn.predict(X_test_scaled)\n",
        "    knn_results[f'kNN (k={k})'] = {\n",
        "        'pred': y_pred_knn,\n",
        "        'acc': accuracy_score(y_test, y_pred_knn)\n",
        "    }\n",
        "\n",
        "def print_evaluation(model_name, y_true, y_pred):\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print_evaluation(\"Decision Tree\", y_test, y_pred_dt)\n",
        "\n",
        "print_evaluation(\"Naïve Bayes\", y_test, y_pred_nb)\n",
        "\n",
        "for k_name, res in knn_results.items():\n",
        "    print_evaluation(k_name, y_test, res['pred'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qm9mlQU5l2K",
        "outputId": "928ab8b7-2684-4d17-a7f5-854dc9833541"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Decision Tree ---\n",
            "Accuracy: 0.7903\n",
            "Confusion Matrix:\n",
            "[[2062  327]\n",
            " [ 302  309]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.87      2389\n",
            "           1       0.49      0.51      0.50       611\n",
            "\n",
            "    accuracy                           0.79      3000\n",
            "   macro avg       0.68      0.68      0.68      3000\n",
            "weighted avg       0.79      0.79      0.79      3000\n",
            "\n",
            "--------------------------------------------------\n",
            "--- Naïve Bayes ---\n",
            "Accuracy: 0.7893\n",
            "Confusion Matrix:\n",
            "[[2338   51]\n",
            " [ 581   30]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.98      0.88      2389\n",
            "           1       0.37      0.05      0.09       611\n",
            "\n",
            "    accuracy                           0.79      3000\n",
            "   macro avg       0.59      0.51      0.48      3000\n",
            "weighted avg       0.71      0.79      0.72      3000\n",
            "\n",
            "--------------------------------------------------\n",
            "--- kNN (k=3) ---\n",
            "Accuracy: 0.8147\n",
            "Confusion Matrix:\n",
            "[[2199  190]\n",
            " [ 366  245]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89      2389\n",
            "           1       0.56      0.40      0.47       611\n",
            "\n",
            "    accuracy                           0.81      3000\n",
            "   macro avg       0.71      0.66      0.68      3000\n",
            "weighted avg       0.80      0.81      0.80      3000\n",
            "\n",
            "--------------------------------------------------\n",
            "--- kNN (k=5) ---\n",
            "Accuracy: 0.8213\n",
            "Confusion Matrix:\n",
            "[[2239  150]\n",
            " [ 386  225]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89      2389\n",
            "           1       0.60      0.37      0.46       611\n",
            "\n",
            "    accuracy                           0.82      3000\n",
            "   macro avg       0.73      0.65      0.67      3000\n",
            "weighted avg       0.80      0.82      0.80      3000\n",
            "\n",
            "--------------------------------------------------\n",
            "--- kNN (k=11) ---\n",
            "Accuracy: 0.8377\n",
            "Confusion Matrix:\n",
            "[[2314   75]\n",
            " [ 412  199]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.97      0.90      2389\n",
            "           1       0.73      0.33      0.45       611\n",
            "\n",
            "    accuracy                           0.84      3000\n",
            "   macro avg       0.79      0.65      0.68      3000\n",
            "weighted avg       0.82      0.84      0.81      3000\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 4:** Evaluation & Cross-Validation"
      ],
      "metadata": {
        "id": "qn4lid8FoQ-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(criterion='entropy', random_state=42),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"kNN (k=3)\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3)),\n",
        "    \"kNN (k=5)\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5)),\n",
        "    \"kNN (k=11)\": make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=11))\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "print(f\"{'Model':<20} | {'70-30 Split':<12} | {'10-Fold CV Mean':<15} | {'Difference'}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for name, model in models.items():\n",
        "    # 1. Calculate Hold-out Accuracy (Step 3 Replication)\n",
        "    model.fit(X_train, y_train)\n",
        "    acc_holdout = model.score(X_test, y_test)\n",
        "\n",
        "    # 2. Calculate 10-Fold Cross-Validation Accuracy\n",
        "    # using 'cross_val_score' which automatically handles the splitting\n",
        "    cv_scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
        "    acc_cv = cv_scores.mean()\n",
        "\n",
        "    diff = acc_cv - acc_holdout\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Holdout': acc_holdout,\n",
        "        'CV_Mean': acc_cv,\n",
        "        'CV_Std': cv_scores.std()\n",
        "    })\n",
        "\n",
        "    print(f\"{name:<20} | {acc_holdout:.4f}       | {acc_cv:.4f}          | {diff:+.4f}\")\n",
        "\n",
        "# Optional: Print Std Dev for stability analysis\n",
        "print(\"\\nStability (Standard Deviation of CV scores):\")\n",
        "for res in results:\n",
        "    print(f\"{res['Model']}: {res['CV_Std']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZWvgN0-hFNC",
        "outputId": "b1590b82-826e-42a0-91f6-2ca04851a7e6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model                | 70-30 Split  | 10-Fold CV Mean | Difference\n",
            "-----------------------------------------------------------------\n",
            "Decision Tree        | 0.7903       | 0.7985          | +0.0082\n",
            "Naive Bayes          | 0.7893       | 0.7845          | -0.0048\n",
            "kNN (k=3)            | 0.8147       | 0.8222          | +0.0075\n",
            "kNN (k=5)            | 0.8213       | 0.8269          | +0.0056\n",
            "kNN (k=11)           | 0.8377       | 0.8344          | -0.0033\n",
            "\n",
            "Stability (Standard Deviation of CV scores):\n",
            "Decision Tree: 0.0105\n",
            "Naive Bayes: 0.0057\n",
            "kNN (k=3): 0.0124\n",
            "kNN (k=5): 0.0122\n",
            "kNN (k=11): 0.0088\n"
          ]
        }
      ]
    }
  ]
}